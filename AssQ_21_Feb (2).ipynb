{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45244f-e4d3-41b3-af28-9f932bd872a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assginment 21 Feb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfd6dac8-213b-4b8c-a8e2-fd10ddc747de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3077a75-f996-4cfa-b05c-50b6094be5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data \n",
    "# is unstructured data in an HTML format.\n",
    "\n",
    "# Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else.\n",
    "# An example would be finding and copying names, Image etc.\n",
    "\n",
    "# Web scraping is used in a variety of digital businesses that rely on data harvesting.\n",
    "# Legitimate use cases include: Search engine bots crawling a site,\n",
    "# analyzing its content and then ranking it.\n",
    "\n",
    "# Image, Name, Price , Serch Engine tools for analysing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4fbe2b-f6ce-48a0-bd61-598f156f0819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f561ab-e8a7-4fbc-9a51-29b9657562f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests: It is a Python module in which you can send HTTP requests to retrieve contents.\n",
    "# It helps you to access website HTML contents or API by sending Get or Post requests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba3c14-dce3-448d-bb57-e2b919ca64e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6dc10a-23a5-4f6a-a172-bc598be18415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3de3ad8-1e13-4bd5-b4c0-0056c95020ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are three main types of data scraping:\n",
    "# Report mining: \n",
    "# Programs pull data from websites into user-generated reports. \n",
    "# It's a bit like printing a page, but the printer is the user's report.\n",
    "# Screen scraping:\n",
    "# The tool pulls information on legacy machines into modern versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2c1c6-4998-4dfe-b5d5-818bcea1ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most common techniques used for Web Scraping are\n",
    "\n",
    "# Human copy-and-paste.\n",
    "# Text pattern matching.\n",
    "# HTTP programming.\n",
    "# HTML parsing.\n",
    "# DOM parsing.\n",
    "# Vertical aggregation.\n",
    "# Semantic annotation recognizing.\n",
    "# Computer vision web-page analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0140f-4cd6-474e-ba75-32054f18573c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a133592-bb78-415d-be2f-337c436797d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0765a73a-1202-4c64-897a-c7ff0d802be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beautiful Soup:-\n",
    "# It is a Python library that is used for web scraping purposes to pull the data out of HTML and XML files.\n",
    "\n",
    "#  It transforms a complex HTML document into a tree of Python objects.\n",
    "# It also automatically converts the document to Unicode, so we don't have to think about encodings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8abe3a7-839e-434b-ad55-98e4942cc9da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aecff39-533d-43b1-a1c6-a15052e8abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e993b19c-0da0-4ca9-a333-577940a78bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flask is a lightweight framework to build websites. We'll use this to parse our collected data and\n",
    "# display it as HTML in a new HTML file. The requests module allows us to send http requests to the website\n",
    "# we want to scrape. The first line imports the Flask class and\n",
    "# the render_template method from the flask library.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc14d52-8ffb-4a77-9a93-13e627f6098d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c23b8e-c066-4229-8527-a374b4685bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60907ce1-f3c0-4ca9-9393-d9f977e819d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Amazon EC2-\n",
    "# You donâ€™t have to invest in costly physical services. Instead, you can create virtual machines with \n",
    "# Amazon EC2 while managing other server features such as ports, security, and storage. \n",
    "\n",
    "#2. Amazon RDS-\n",
    "# The Amazon Relational Database Service (RDS) was designed to make your infrastructure more user friendly.\n",
    "# By using this AWS service, you can create dedicated instances of databases within minutes.\n",
    "\n",
    "#3 Amazon Simple Storage Service (S3)-\n",
    "# We are living in the age of big data. Some call it the incessant data deluge. \n",
    "# As a result, we need more storage than ever before. Amazon Simple Storage Service (S3) has come to the rescue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
